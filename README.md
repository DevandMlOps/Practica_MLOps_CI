# MLOps Breast Cancer Prediction - GitHub Actions CI/CD Pipeline

## Tabla de Contenidos
- [Descripci√≥n General](#descripci√≥n-general)
- [Arquitectura del Pipeline](#arquitectura-del-pipeline)
- [Configuraci√≥n Inicial](#configuraci√≥n-inicial)
- [Estructura del Workflow](#estructura-del-workflow)
- [Jobs y Etapas Detalladas](#jobs-y-etapas-detalladas)
- [Secretos y Variables](#secretos-y-variables)
- [Triggers del Pipeline](#triggers-del-pipeline)
- [Logs y Debugging](#logs-y-debugging)
- [Mejores Pr√°cticas Implementadas](#mejores-pr√°cticas-implementadas)
- [Troubleshooting](#troubleshooting)

## Descripci√≥n General

Este proyecto implementa un pipeline completo de CI/CD (Continuous Integration/Continuous Deployment) usando GitHub Actions para automatizar el ciclo de vida completo de un modelo de Machine Learning para diagn√≥stico de c√°ncer de mama. El pipeline garantiza que cada cambio en el c√≥digo pase por un proceso riguroso de validaci√≥n antes de ser desplegado.

### Componentes del Sistema
- **Modelo de ML**: Clasificador de c√°ncer de mama usando Regresi√≥n Log√≠stica
- **API REST**: Servicio Flask que expone el modelo
- **Containerizaci√≥n**: Docker para empaquetado reproducible
- **CI/CD**: GitHub Actions para automatizaci√≥n completa

## Arquitectura del Pipeline

```mermaid
graph TD
    A[Push/PR a main] --> B[Trigger GitHub Actions]
    B --> C[Job: build_and_test]
    C --> D[Setup Python 3.11]
    D --> E[Instalar Dependencias]
    E --> F[Generar Dataset]
    F --> G[Entrenar Modelo]
    G --> H[Construir Docker Image]
    H --> I[Ejecutar Container]
    I --> J[Ejecutar Tests API]
    J --> K{Tests Pass?}
    K -->|No| L[Pipeline Fail]
    K -->|Yes| M{Es Push a main?}
    M -->|No| N[Pipeline Success]
    M -->|Yes| O[Job: push_to_registry]
    O --> P[Login Docker Hub]
    P --> Q[Rebuild & Push Image]
    Q --> R[Deploy Success]
```

## Configuraci√≥n Inicial

### 1. Configurar Secretos en GitHub

Navega a tu repositorio de GitHub y configura los siguientes secretos:

1. Ve a `Settings` > `Secrets and variables` > `Actions`
2. Haz click en `New repository secret`
3. Agrega los siguientes secretos:

#### Secretos Requeridos

| Nombre | Descripci√≥n | Ejemplo |
|--------|-------------|---------|
| `DOCKERHUB_USERNAME` | Tu nombre de usuario de Docker Hub | `tu_usuario` |
| `DOCKERHUB_TOKEN` | Token de acceso de Docker Hub | `dckr_pat_...` |

#### Generar Token de Docker Hub

1. Ve a [Docker Hub](https://hub.docker.com)
2. Navega a `Account Settings` > `Security`
3. Click en `New Access Token`
4. Asigna nombre: "GitHub Actions Token"
5. Selecciona permisos: `Read, Write, Delete`
6. Copia el token generado (solo se muestra una vez)

### 2. Estructura de Archivos Requerida

```
.github/
‚îî‚îÄ‚îÄ workflows/
    ‚îî‚îÄ‚îÄ ci-cd.yml          # Archivo principal del workflow
```

## Estructura del Workflow

### Archivo: `.github/workflows/ci-cd.yml`

```yaml
name: CI/CD Pipeline - Modelo y API

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

env:
  DOCKER_IMAGE_NAME: ${{ secrets.DOCKERHUB_USERNAME }}/mlops-breast-cancer

jobs:
  build_and_test:
    runs-on: ubuntu-latest
    
    steps:
      - name: 1. Clonar el repositorio
        uses: actions/checkout@v4

      - name: 2. Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: 3. Instalar dependencias
        run: pip install -r requirements.txt
      
      - name: 4. Generar el dataset
        run: python data/load_data.py
        
      - name: 5. Entrenar el modelo
        run: python model/train.py
          
      - name: 6. Construir la imagen Docker
        run: docker build -t $DOCKER_IMAGE_NAME:latest .

      - name: 7. Ejecutar el contenedor para las pruebas
        run: docker run -d --name api-container -p 5000:5000 $DOCKER_IMAGE_NAME:latest

      - name: 8. Ejecutar pruebas de API
        run: python tests/test_api.py

  push_to_registry:
    needs: build_and_test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest

    steps:
      - name: 1. Clonar el repositorio
        uses: actions/checkout@v4
      
      - name: 2. Iniciar sesi√≥n en Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
          
      - name: 3. Entrenar modelo y construir imagen
        run: |
          pip install -r requirements.txt
          python data/load_data.py
          python model/train.py
          docker build -t $DOCKER_IMAGE_NAME:latest .
      
      - name: 4. Empujar la imagen a Docker Hub
        run: docker push $DOCKER_IMAGE_NAME:latest
```

## Jobs y Etapas Detalladas

### Job 1: `build_and_test`

Este job se ejecuta en **todos** los pushes y pull requests a la rama main. Su prop√≥sito es validar que el c√≥digo funciona correctamente.

#### Etapa 1: Clonar Repositorio
```yaml
- name: 1. Clonar el repositorio
  uses: actions/checkout@v4
```
- **Prop√≥sito**: Descarga el c√≥digo fuente del repositorio
- **Action usada**: `actions/checkout@v4` (versi√≥n estable)
- **Resultado**: El runner tiene acceso a todos los archivos del proyecto

#### Etapa 2: Configurar Python
```yaml
- name: 2. Configurar Python
  uses: actions/setup-python@v4
  with:
    python-version: '3.11'
```
- **Prop√≥sito**: Instala Python 3.11 en el runner
- **Action usada**: `actions/setup-python@v4`
- **Por qu√© Python 3.11**: Compatibilidad con todas las librer√≠as y rendimiento √≥ptimo
- **Resultado**: Python y pip disponibles en el PATH

#### Etapa 3: Instalar Dependencias
```yaml
- name: 3. Instalar dependencias
  run: pip install -r requirements.txt
```
- **Prop√≥sito**: Instala todas las librer√≠as Python necesarias
- **Archivos involucrados**: `requirements.txt`
- **Duraci√≥n t√≠pica**: 30-60 segundos
- **Posibles errores**: Conflictos de versiones, dependencias faltantes

#### Etapa 4: Generar Dataset
```yaml
- name: 4. Generar el dataset
  run: python data/load_data.py
```
- **Prop√≥sito**: Crea el archivo `breast-cancer.csv` desde scikit-learn
- **Archivos generados**: `data/breast-cancer.csv`
- **Por qu√© no usar dataset externo**: Evita dependencias externas y problemas de descarga
- **Duraci√≥n t√≠pica**: 5-10 segundos

#### Etapa 5: Entrenar Modelo
```yaml
- name: 5. Entrenar el modelo
  run: python model/train.py
```
- **Prop√≥sito**: Entrena el modelo y genera artefactos
- **Archivos generados**:
  - `model/breast_cancer_model.joblib`
  - `model/scaler.joblib`
  - `model/model_metadata.json`
- **Duraci√≥n t√≠pica**: 10-30 segundos
- **Validaciones**: El script valida datos y reporta m√©tricas

#### Etapa 6: Construir Imagen Docker
```yaml
- name: 6. Construir la imagen Docker
  run: docker build -t $DOCKER_IMAGE_NAME:latest .
```
- **Prop√≥sito**: Crea la imagen Docker con la aplicaci√≥n
- **Archivos involucrados**: `Dockerfile`, c√≥digo de la API, modelo entrenado
- **Tag usado**: `latest` para identificar la versi√≥n m√°s reciente
- **Duraci√≥n t√≠pica**: 60-120 segundos

#### Etapa 7: Ejecutar Container
```yaml
- name: 7. Ejecutar el contenedor para las pruebas
  run: docker run -d --name api-container -p 5000:5000 $DOCKER_IMAGE_NAME:latest
```
- **Prop√≥sito**: Levanta el contenedor para realizar pruebas
- **Par√°metros importantes**:
  - `-d`: Ejecuta en background (daemon)
  - `--name`: Asigna nombre al contenedor para referencia
  - `-p 5000:5000`: Mapea puerto del host al contenedor
- **Resultado**: API REST corriendo en `http://localhost:5000`

#### Etapa 8: Ejecutar Tests
```yaml
- name: 8. Ejecutar pruebas de API
  run: python tests/test_api.py
```
- **Prop√≥sito**: Valida que la API funciona correctamente
- **Tests ejecutados**:
  - Health check (`GET /`)
  - Predicci√≥n v√°lida (`POST /predict`)
  - Manejo de datos inv√°lidos
- **L√≥gica de espera**: El script espera hasta 60 segundos a que la API est√© lista
- **Criterio de fallo**: Si cualquier test falla, todo el job falla

### Job 2: `push_to_registry`

Este job **solo se ejecuta** cuando:
1. El job `build_and_test` termina exitosamente
2. El evento es un `push` (no pull request)
3. El push es a la rama `main`

#### Condiciones de Ejecuci√≥n
```yaml
needs: build_and_test
if: github.event_name == 'push' && github.ref == 'refs/heads/main'
```

#### Etapa 1: Clonar Repositorio
- Id√©ntica al Job 1

#### Etapa 2: Login a Docker Hub
```yaml
- name: 2. Iniciar sesi√≥n en Docker Hub
  uses: docker/login-action@v3
  with:
    username: ${{ secrets.DOCKERHUB_USERNAME }}
    password: ${{ secrets.DOCKERHUB_TOKEN }}
```
- **Prop√≥sito**: Autenticar con Docker Hub para poder hacer push
- **Seguridad**: Usa secretos de GitHub, no credenciales hardcodeadas
- **Action usada**: `docker/login-action@v3` - acci√≥n oficial de Docker

#### Etapa 3: Reconstruir Imagen
```yaml
- name: 3. Entrenar modelo y construir imagen
  run: |
    pip install -r requirements.txt
    python data/load_data.py
    python model/train.py
    docker build -t $DOCKER_IMAGE_NAME:latest .
```
- **Por qu√© reconstruir**: Los jobs de GitHub Actions no comparten artefactos por defecto
- **Proceso completo**: Repite el entrenamiento para garantizar consistencia
- **Tiempo adicional**: ~2-3 minutos extra, pero garantiza reproducibilidad

#### Etapa 4: Push a Registry
```yaml
- name: 4. Empujar la imagen a Docker Hub
  run: docker push $DOCKER_IMAGE_NAME:latest
```
- **Prop√≥sito**: Publica la imagen validada en Docker Hub
- **Tag**: `latest` indica la versi√≥n m√°s reciente
- **Disponibilidad**: La imagen estar√° disponible p√∫blicamente

## Secretos y Variables

### Variables de Entorno

#### A Nivel de Workflow
```yaml
env:
  DOCKER_IMAGE_NAME: ${{ secrets.DOCKERHUB_USERNAME }}/mlops-breast-cancer
```
- **Prop√≥sito**: Evita repetir el nombre de la imagen
- **Formato**: `usuario/repositorio`
- **Uso**: Se referencia como `$DOCKER_IMAGE_NAME` en los steps

#### A Nivel de Job/Step
Los jobs pueden definir variables espec√≠ficas si es necesario.

### Gesti√≥n de Secretos

#### Buenas Pr√°cticas Implementadas
1. **Nunca hardcodear credenciales** en el c√≥digo
2. **Usar secretos de GitHub** para informaci√≥n sensible
3. **Principio de menor privilegio** en tokens
4. **Rotaci√≥n regular** de tokens de acceso

#### Seguridad
- Los secretos est√°n encriptados en GitHub
- Solo son accesibles durante la ejecuci√≥n del workflow
- No aparecen en logs (GitHub los enmascara autom√°ticamente)

## Triggers del Pipeline

### Eventos que Activan el Workflow

#### Push a Main
```yaml
on:
  push:
    branches: [ "main" ]
```
- **Cu√°ndo**: Al hacer `git push origin main`
- **Qu√© ejecuta**: Ambos jobs (`build_and_test` + `push_to_registry`)
- **Prop√≥sito**: Deploy autom√°tico de cambios validados

#### Pull Requests
```yaml
on:
  pull_request:
    branches: [ "main" ]
```
- **Cu√°ndo**: Al crear/actualizar PR hacia main
- **Qu√© ejecuta**: Solo `build_and_test`
- **Prop√≥sito**: Validaci√≥n antes de merge

### Flujo T√≠pico de Desarrollo

1. **Desarrollo local**: Desarrollador trabaja en feature branch
2. **Push a feature branch**: No activa el workflow
3. **Crear PR**: Activa `build_and_test` para validaci√≥n
4. **Review y approve**: Process manual de code review
5. **Merge a main**: Activa workflow completo con deploy

## Logs y Debugging

### Acceder a los Logs

1. Ve a tu repositorio en GitHub
2. Click en la pesta√±a `Actions`
3. Selecciona el workflow run espec√≠fico
4. Click en el job que quieres inspeccionar
5. Expande el step espec√≠fico

### Estructura de Logs

#### Log de Entreamiento
```
üß† Iniciando entrenamiento del modelo...
üìä Cargando datos...
Dataset cargado desde: /home/runner/work/proyecto/data/breast-cancer.csv
Dataset cargado: 569 filas, 32 columnas
Distribuci√≥n de clases:
diagnosis
0    357
1    212
üìè Normalizando datos...
üéØ Entrenando modelo de Regresi√≥n Log√≠stica...
üìä Evaluando modelo...

‚úÖ Precisi√≥n del modelo: 0.9649
```

#### Log de Tests
```
üß™ Iniciando tests de la API...
‚è≥ Esperando que la API est√© lista...
‚úÖ API est√° respondiendo

üîç Probando endpoint de health check...
Status code: 200
‚úÖ Health Check: PASSED

üîç Probando predicci√≥n con datos v√°lidos...
Status code: 200
‚úÖ Predicci√≥n v√°lida: PASSED
```

### Debugging Com√∫n

#### Container No Responde
```yaml
- name: Debug - Ver logs del container
  run: docker logs api-container
```

#### Verificar Archivos Generados
```yaml
- name: Debug - Listar archivos del modelo
  run: ls -la model/
```

#### Test de Conectividad
```yaml
- name: Debug - Test manual de API
  run: |
    curl -f http://localhost:5000/ || exit 1
    curl -X POST http://localhost:5000/predict \
      -H "Content-Type: application/json" \
      -d '{"features": [17.99, 10.38, ...]}' || exit 1
```

## Mejores Pr√°cticas Implementadas

### 1. Separaci√≥n de Concerns
- **Testing separado de Deploy**: Dos jobs independientes
- **Validaci√≥n antes de publicaci√≥n**: Solo deploys exitosos
- **Fail fast**: Falla r√°pido si hay problemas

### 2. Reproducibilidad
- **Versiones fijas** de Python y actions
- **Dataset determin√≠stico** generado desde c√≥digo
- **Seed fijo** en algoritmos de ML (random_state=42)

### 3. Seguridad
- **Secretos encriptados** para credenciales
- **Tokens con permisos m√≠nimos** necesarios
- **No exposici√≥n** de informaci√≥n sensible en logs

### 4. Eficiencia
- **Cach√© impl√≠cito** de capas Docker
- **Paralelizaci√≥n** donde es posible
- **Early termination** en caso de fallos

### 5. Monitoreo
- **Logs estructurados** para debugging
- **Status checks** claros en GitHub
- **M√©tricas del modelo** reportadas en logs

## Troubleshooting

### Problemas Comunes y Soluciones

#### 1. Error: "docker: command not found"
**S√≠ntoma**: El comando docker no se reconoce
**Causa**: Docker no est√° instalado en el runner
**Soluci√≥n**: Los runners de GitHub Actions incluyen Docker por defecto. Verificar la imagen del runner.

#### 2. Error: "No such file or directory: model/*.joblib"
**S√≠ntoma**: La API no encuentra los archivos del modelo
**Causa**: El entrenamiento fall√≥ o no se copiaron los archivos al container
**Soluci√≥n**: 
```yaml
- name: Debug - Verificar archivos
  run: |
    ls -la model/
    docker exec api-container ls -la model/
```

#### 3. Error: "unauthorized: authentication required"
**S√≠ntoma**: No puede hacer push a Docker Hub
**Causa**: Credenciales incorrectas o token expirado
**Soluci√≥n**: 
- Verificar que los secretos est√©n configurados correctamente
- Regenerar token en Docker Hub si es necesario

#### 4. Error: "Tests failed - API not responding"
**S√≠ntoma**: Los tests fallan porque no pueden conectar a la API
**Causa**: El container no inici√≥ correctamente o toma mucho tiempo
**Soluci√≥n**:
```yaml
- name: Wait for API
  run: |
    for i in {1..30}; do
      if curl -f http://localhost:5000/; then
        break
      fi
      echo "Waiting for API... ($i/30)"
      sleep 2
    done
```

#### 5. Error: "Python package not found"
**S√≠ntoma**: ImportError durante la ejecuci√≥n
**Causa**: Dependencia faltante en requirements.txt
**Soluci√≥n**: Verificar que todas las dependencias est√©n listadas con versiones espec√≠ficas

### Estrategias de Debug Avanzado

#### 1. Debug Mode en Workflow
```yaml
- name: Enable debug logging
  run: echo "RUNNER_DEBUG=1" >> $GITHUB_ENV
```

#### 2. SSH Debug (para casos extremos)
```yaml
- name: Setup tmate session
  uses: mxschmitt/action-tmate@v3
  if: failure()
```

#### 3. Artifact Collection
```yaml
- name: Upload logs
  uses: actions/upload-artifact@v3
  if: failure()
  with:
    name: debug-logs
    path: logs/
```

### Optimizaciones Avanzadas

#### 1. Cach√© de Dependencias
```yaml
- name: Cache pip dependencies
  uses: actions/cache@v3
  with:
    path: ~/.cache/pip
    key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
```

#### 2. Matrix Testing
```yaml
strategy:
  matrix:
    python-version: [3.9, 3.10, 3.11]
```

#### 3. Conditional Steps
```yaml
- name: Deploy to staging
  if: github.ref == 'refs/heads/develop'
  run: echo "Deploy to staging environment"
```

---

## Conclusi√≥n

Este pipeline de CI/CD implementa las mejores pr√°cticas de MLOps moderno, asegurando que cada cambio pase por un proceso riguroso de validaci√≥n antes del despliegue. La automatizaci√≥n completa reduce errores humanos y garantiza reproducibilidad en todos los entornos.

### Beneficios Clave
- **Automatizaci√≥n completa** del proceso de despliegue
- **Validaci√≥n rigurosa** antes de cada deploy
- **Reproducibilidad** garantizada en cualquier entorno
- **Trazabilidad** completa de cambios y deployments
- **Seguridad** mediante el uso de secretos encriptados

El pipeline est√° dise√±ado para ser mantenible, escalable y f√°cil de entender, facilitando tanto el desarrollo como la operaci√≥n del sistema de ML en producci√≥n.
