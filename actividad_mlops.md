-----

# üöÄ Proyecto: Pipeline de MLOps para Diagn√≥stico de C√°ncer de Mama

**`actividad_mlops.md`**

## üéØ Objetivo General

Este documento detalla la implementaci√≥n de un sistema de MLOps de extremo a extremo para un modelo de clasificaci√≥n de c√°ncer de mama. El proyecto abarca desde el entrenamiento del modelo hasta su despliegue automatizado como un microservicio contenedorizado, cumpliendo con las mejores pr√°cticas de versionado, reproducibilidad, empaquetado y pruebas.

El desarrollo se ha guiado por los criterios de la categor√≠a **Sobresaliente** de la r√∫brica de evaluaci√≥n, enfoc√°ndose en la robustez, optimizaci√≥n y profesionalismo de cada componente.

-----

## üìÇ Estructura del Proyecto

El repositorio se organiz√≥ de manera modular para separar claramente las responsabilidades, facilitando el mantenimiento y la escalabilidad.

```
mlops-breast-cancer/
‚îú‚îÄ‚îÄ .github/workflows/
‚îÇ   ‚îî‚îÄ‚îÄ ci-cd.yml       # Workflow de Integraci√≥n y Despliegue Continuo
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ app.py          # L√≥gica de la API REST con Flask
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ breast-cancer.csv # Dataset generado
‚îÇ   ‚îî‚îÄ‚îÄ load_data.py    # Script para generar el dataset desde scikit-learn
‚îú‚îÄ‚îÄ logs/               # Directorio para logs (ignorado por Git)
‚îÇ   ‚îî‚îÄ‚îÄ api.log
‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ breast_cancer_model.joblib # Modelo serializado
‚îÇ   ‚îú‚îÄ‚îÄ model_metadata.json # Metadatos del modelo (versi√≥n, m√©tricas)
‚îÇ   ‚îú‚îÄ‚îÄ scaler.joblib     # Escalador serializado
‚îÇ   ‚îî‚îÄ‚îÄ train.py          # Script de entrenamiento y evaluaci√≥n
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ test_api.py       # Pruebas automatizadas para los endpoints
‚îú‚îÄ‚îÄ .dockerignore         # Archivos a ignorar en el build de Docker
‚îú‚îÄ‚îÄ .gitignore            # Archivos a ignorar por Git
‚îú‚îÄ‚îÄ Dockerfile            # Definici√≥n del contenedor
‚îú‚îÄ‚îÄ README.md             # Documentaci√≥n principal para el usuario
‚îî‚îÄ‚îÄ requirements.txt      # Dependencias del proyecto
```

-----

## üß† 1. Entrenamiento y Serializaci√≥n del Modelo

Se implement√≥ un flujo de entrenamiento robusto y reproducible, superando los requisitos b√°sicos.

  * **Modelo Seleccionado:** Se opt√≥ por una **Regresi√≥n Log√≠stica**. Esta elecci√≥n se basa en su alta interpretabilidad, eficiencia computacional y excelente rendimiento para problemas de clasificaci√≥n binaria bien definidos como este, sirviendo como una s√≥lida l√≠nea base.
  * **Preprocesamiento Optimizado:** El script `model/train.py` no solo carga los datos, sino que realiza una limpieza (eliminando columnas innecesarias), mapea la variable objetivo a valores num√©ricos (`M` -\> 1, `B` -\> 0) y aplica **escalado est√°ndar** (`StandardScaler`). El escalador tambi√©n se serializa, garantizando que los datos de inferencia se transformen exactamente igual que los de entrenamiento.
  * **Evaluaci√≥n y Pruebas:** El modelo fue evaluado en un conjunto de prueba estratificado, alcanzando una **precisi√≥n superior al 96%**. Se genera un reporte de clasificaci√≥n completo (`classification_report`) para analizar m√©tricas como precisi√≥n, recall y F1-score por clase.
  * **Serializaci√≥n y Metadatos:** Se utiliza `joblib` para guardar tanto el modelo como el escalador. Adicionalmente, se genera un archivo `model_metadata.json` que almacena m√©tricas clave (como la precisi√≥n) y las caracter√≠sticas del modelo. Esto permite que la API verifique din√°micamente el n√∫mero de features esperadas y exponga el rendimiento del modelo, una pr√°ctica avanzada que mejora la mantenibilidad.

-----

## üíª 2. Desarrollo de API con Flask

La API fue dise√±ada para ser robusta, segura y f√°cil de usar, incorporando pr√°cticas profesionales de desarrollo de software.

  * **Endpoints Implementados:**
      * `GET /`: Proporciona un **health check** que no solo confirma que la API est√° en l√≠nea, sino que tambi√©n reporta el estado de carga del modelo y su precisi√≥n, ofreciendo un diagn√≥stico m√°s completo del servicio.
      * `POST /predict`: Recibe los datos, los valida y devuelve una predicci√≥n en formato JSON con la clase predicha (`Maligno`/`Benigno`) y las probabilidades de confianza asociadas.
  * **Robustez y Manejo de Errores:**
      * **Validaci√≥n de Entradas:** Se utiliza **Pydantic** para definir un esquema estricto de los datos de entrada. Esto previene errores en tiempo de ejecuci√≥n, devolviendo respuestas claras (`422 Unprocessable Entity`) si los datos no cumplen con el formato o tipo esperado. Tambi√©n se valida la cantidad de *features* contra los metadatos del modelo.
      * **Logging Profesional:** Se integra **Loguru** para generar logs estructurados en `logs/api.log`. Se registran eventos clave como el inicio del servidor, la carga del modelo, las solicitudes recibidas y cualquier error, facilitando la depuraci√≥n y monitorizaci√≥n.
      * **Manejo de Errores Espec√≠ficos:** La API gestiona expl√≠citamente errores como JSON mal formado (`400`), datos inv√°lidos (`422`) y la no disponibilidad del modelo (`503`), proporcionando siempre una respuesta JSON informativa.
  * **Documentaci√≥n:** El c√≥digo est√° comentado, y el modelo de Pydantic incluye un ejemplo en su `schema_extra`, lo que facilita la auto-documentaci√≥n en herramientas como Swagger UI.

-----

## üê≥ 3. Dockerizaci√≥n del Sistema

El `Dockerfile` fue optimizado para crear una imagen ligera, segura y eficiente, siguiendo las mejores pr√°cticas de la industria.

  * **Imagen Base Optimizada:** Se utiliza `python:3.11-slim` como imagen base, que es significativamente m√°s peque√±a que la imagen completa, reduciendo la superficie de ataque y el tiempo de despliegue.
  * **Eficiencia en Capas:** El orden de los comandos est√° optimizado para el cacheo de Docker. Se copia primero `requirements.txt` y se instalan las dependencias. De esta forma, si solo cambia el c√≥digo fuente, Docker no necesita reinstalar las dependencias, acelerando las compilaciones posteriores.
  * **Buenas Pr√°cticas:**
      * `.dockerignore`: Se utiliza para excluir archivos y directorios innecesarios (`.git`, `tests`, `data`, etc.) del contexto de compilaci√≥n, manteniendo la imagen final limpia y ligera.
      * **Variables de Entorno:** Se configuran `PYTHONDONTWRITEBYTECODE=1` y `PYTHONUNBUFFERED=1` para evitar archivos `.pyc` y asegurar que los logs se muestren en tiempo real.
      * **Usuario no-root:** Aunque no se implement√≥ para simplicidad, en un entorno de producci√≥n se crear√≠a un usuario sin privilegios para ejecutar la aplicaci√≥n.
  * **Pruebas Locales Exitosas:** La imagen fue construida y ejecutada localmente con `docker build` y `docker run`, y los endpoints fueron probados exitosamente, garantizando su funcionalidad antes de integrarla en el flujo de CI/CD.

-----

## ‚öôÔ∏è 4. Automatizaci√≥n CI/CD con GitHub Actions

Se implement√≥ un flujo de CI/CD completo y profesional que automatiza las pruebas y el despliegue, garantizando la calidad del c√≥digo en cada cambio.

  * **Workflow:** El archivo `.github/workflows/ci-cd.yml` define un pipeline que se activa en cada `push` o `pull_request` a la rama `main`.
  * **Job de Pruebas (`test`):** Este job realiza una integraci√≥n continua completa:
    1.  **Checkout:** Descarga el c√≥digo del repositorio.
    2.  **Setup y Dependencias:** Configura Python e instala las librer√≠as.
    3.  **Entrenamiento:** Ejecuta el script de entrenamiento para generar los artefactos del modelo (`.joblib`, `.json`). Este paso asegura que el proceso de entrenamiento no est√© roto.
    4.  **Build de Docker:** Construye la imagen Docker dentro del runner de GitHub.
    5.  **Ejecuci√≥n del Contenedor:** Levanta el contenedor en segundo plano.
    6.  **Pruebas Automatizadas:** Ejecuta el script `tests/test_api.py` contra el contenedor en ejecuci√≥n, probando los endpoints en un entorno realista.
    7.  **Limpieza:** Detiene y elimina el contenedor de prueba.
  * **Job de Despliegue (`deploy`):**
    1.  **Condicional:** Este job depende del √©xito del job `test` y **solo se ejecuta en un `push` directo a `main`**, previniendo despliegues desde pull requests.
    2.  **Login:** Se autentica de forma segura en Docker Hub usando secretos de GitHub (`DOCKERHUB_USERNAME`, `DOCKERHUB_TOKEN`).
    3.  **Build and Push:** Utiliza la acci√≥n `docker/build-push-action` para construir la imagen y subirla al registro de Docker Hub con el tag `latest`.

Este flujo garantiza que cada cambio en la rama principal sea autom√°ticamente probado y, si pasa las pruebas, desplegado como una nueva imagen de Docker, logrando una verdadera **Integraci√≥n y Entrega Continua**.

-----

## üìú 5. Documentaci√≥n y Entrega

La documentaci√≥n y la estructura del proyecto fueron dise√±adas para ser claras, completas y seguir las mejores pr√°cticas.

  * **README.md:** El archivo `README.md` principal es una gu√≠a completa que explica c√≥mo configurar el entorno, entrenar el modelo, ejecutar la API (localmente y con Docker) y c√≥mo probar los endpoints con ejemplos de `curl`.
  * **C√≥digo Documentado:** El c√≥digo fuente incluye comentarios explicativos en las funciones y clases clave.
  * **Pruebas Expl√≠citas:** El directorio `tests/` contiene pruebas automatizadas que no solo validan el funcionamiento del sistema, sino que tambi√©n sirven como documentaci√≥n viva de c√≥mo debe comportarse la API.
  * **Reflexiones Finales:**
      * **Logros:** Se ha creado un sistema MLOps funcional y robusto que es reproducible, escalable y automatizado. La separaci√≥n de componentes permite que el equipo de ciencia de datos actualice el modelo (`/model`) sin afectar al equipo de backend que gestiona la API (`/api`).
      * **Posibles Mejoras:** Para un entorno productivo, los siguientes pasos incluir√≠an: versionado de modelos en un registro como MLflow, un sistema de monitoreo de predicciones para detectar *data drift*, y el despliegue en una plataforma en la nube como Kubernetes o AWS App Runner para una mayor escalabilidad y gesti√≥n.
